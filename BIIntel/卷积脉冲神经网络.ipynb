{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33791de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x2824dea90>\n",
      "CSNN(\n",
      "  (conv_fc): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=m)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (2): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=m)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (6): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1, step_mode=m)\n",
      "    (9): Linear(in_features=6272, out_features=2048, bias=False)\n",
      "    (10): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (11): Linear(in_features=2048, out_features=10, bias=False)\n",
      "    (12): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26421880/26421880 [07:09<00:00, 61514.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29515/29515 [00:00<00:00, 57103.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4422102/4422102 [00:51<00:00, 86463.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5148/5148 [00:00<00:00, 4254635.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./fashionmnist/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Adam",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8f/wcsnxjv12_g1qf74g56xwkwr0000gn/T/ipykernel_99106/3345642828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/8f/wcsnxjv12_g1qf74g56xwkwr0000gn/T/ipykernel_99106/3345642828.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Adam"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "\n",
    "\n",
    "#卷积脉冲神经网络定义\n",
    "class CSNN(nn.Module):\n",
    "    def __init__(self, T: int, channels: int, use_cupy=False):\n",
    "        super().__init__()\n",
    "        self.T = T  #SNN时间步长\n",
    "\n",
    "        self.conv_fc = nn.Sequential(\n",
    "        layer.Conv2d(1, channels, kernel_size=3, padding=1, bias=False),    #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 # IF脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 14 * 14                                   # 最大池化\n",
    "\n",
    "        layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False), #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 7 * 7                                     # 最大池化\n",
    "\n",
    "        layer.Flatten(),\n",
    "        layer.Linear(channels * 7 * 7, channels * 4 * 4, bias=False),       #普通线性层\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "\n",
    "        layer.Linear(channels * 4 * 4, 10, bias=False),         \n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "        functional.set_step_mode(self, step_mode='m')                       #多步脉冲模式\n",
    "\n",
    "        if use_cupy:\n",
    "            functional.set_backend(self, backend='cupy')\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x.shape = [N, C, H, W]\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)  # [N, C, H, W] -> [T, N, C, H, W]  #将数据复制T份直接输入网络\n",
    "        x_seq = self.conv_fc(x_seq)\n",
    "        fr = x_seq.mean(0)\n",
    "        return fr\n",
    "    \n",
    "    def spiking_encoder(self):\n",
    "        return self.conv_fc[0:3] #脉冲节点即可将float输入编码为spike序列\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    (sj-dev) wfang@Precision-5820-Tower-X-Series:~/spikingjelly_dev$ python -m spikingjelly.activation_based.examples.conv_fashion_mnist -h\n",
    "\n",
    "    usage: conv_fashion_mnist.py [-h] [-T T] [-device DEVICE] [-b B] [-epochs N] [-j N] [-data-dir DATA_DIR] [-out-dir OUT_DIR]\n",
    "                                 [-resume RESUME] [-amp] [-cupy] [-opt OPT] [-momentum MOMENTUM] [-lr LR]\n",
    "\n",
    "    Classify Fashion-MNIST\n",
    "\n",
    "    optional arguments:\n",
    "      -h, --help          show this help message and exit\n",
    "      -T T                simulating time-steps\n",
    "      -device DEVICE      device\n",
    "      -b B                batch size\n",
    "      -epochs N           number of total epochs to run\n",
    "      -j N                number of data loading workers (default: 4)\n",
    "      -data-dir DATA_DIR  root dir of Fashion-MNIST dataset\n",
    "      -out-dir OUT_DIR    root dir for saving logs and checkpoint\n",
    "      -resume RESUME      resume from the checkpoint path\n",
    "      -amp                automatic mixed precision training\n",
    "      -cupy               use cupy neuron and multi-step forward mode\n",
    "      -opt OPT            use which optimizer. SDG or Adam\n",
    "      -momentum MOMENTUM  momentum for SGD\n",
    "      -save-es            dir for saving a batch spikes encoded by the first {Conv2d-BatchNorm2d-IFNode}\n",
    "    '''\n",
    "    # python -m spikingjelly.activation_based.examples.conv_fashion_mnist -T 4 -device cuda:0 -b 128 -epochs 64 -data-dir /datasets/FashionMNIST/ -amp -cupy -opt sgd -lr 0.1 -j 8\n",
    "\n",
    "    # python -m spikingjelly.activation_based.examples.conv_fashion_mnist -T 4 -device cuda:0 -b 4 -epochs 64 -data-dir /datasets/FashionMNIST/ -amp -cupy -opt sgd -lr 0.1 -j 8 -resume ./logs/T4_b256_sgd_lr0.1_c128_amp_cupy/checkpoint_latest.pth -save-es ./logs\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description='Classify Fashion-MNIST')\n",
    "    parser.add_argument('-T', default=4, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', default=128, type=int, help='batch size')\n",
    "    parser.add_argument('-epochs', default=64, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('-data-dir', type=str, help='root dir of Fashion-MNIST dataset')\n",
    "    parser.add_argument('-out-dir', type=str, default='./logs', help='root dir for saving logs and checkpoint')\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    parser.add_argument('-amp', action='store_true', help='automatic mixed precision training')\n",
    "    parser.add_argument('-cupy', action='store_true', help='use cupy backend')\n",
    "    parser.add_argument('-opt', type=str, help='use which optimizer. SDG or Adam')\n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-lr', default=0.1, type=float, help='learning rate')\n",
    "    parser.add_argument('-channels', default=128, type=int, help='channels of CSNN')\n",
    "    parser.add_argument('-save-es', default=None, help='dir for saving a batch spikes encoded by the first {Conv2d-BatchNorm2d-IFNode}')\n",
    "    '''\n",
    "    \n",
    "    class parser():\n",
    "        def __init__(self):\n",
    "            self.T = 4\n",
    "            self.device = 'cpu'\n",
    "            self.b = 128\n",
    "            self.epochs = 64\n",
    "            self.j = 4\n",
    "            self.data_dir='./fashionmnist'\n",
    "            self.out_dir='logs'\n",
    "            self.resume = 'None'\n",
    "            self.amp = False\n",
    "            self.cupy = False\n",
    "            self.opt = 'Adam'\n",
    "            self.momentum = 0.9\n",
    "            self.lr = 0.1\n",
    "            self.channels = 128\n",
    "            self.save_es = None\n",
    "    \n",
    "    #args = parser.parse_args()\n",
    "    args = parser()\n",
    "    print(args)\n",
    "\n",
    "    net = CSNN(T=args.T, channels=args.channels, use_cupy=args.cupy)\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    net.to(args.device)\n",
    "    \n",
    "    '''\n",
    "    载入数据，和普通DNN的训练步骤一样\n",
    "    '''\n",
    "\n",
    "    train_set = torchvision.datasets.FashionMNIST(\n",
    "            root=args.data_dir,\n",
    "            train=True,\n",
    "            transform=torchvision.transforms.ToTensor(),\n",
    "            download=True)\n",
    "\n",
    "    test_set = torchvision.datasets.FashionMNIST(\n",
    "            root=args.data_dir,\n",
    "            train=False,\n",
    "            transform=torchvision.transforms.ToTensor(),\n",
    "            download=True)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=args.b,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=args.b,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "\n",
    "    scaler = None\n",
    "    if args.amp:\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "    start_epoch = 0\n",
    "    max_test_acc = -1\n",
    "\n",
    "    '''\n",
    "    定义优化器，和普通DNN的训练步骤一样\n",
    "    '''\n",
    "    \n",
    "    optimizer = None\n",
    "    if args.opt == 'sgd':\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    elif args.opt == 'adam':\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        raise NotImplementedError(args.opt)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "\n",
    "\n",
    "    out_dir = os.path.join(args.out_dir, f'T{args.T}_b{args.b}_{args.opt}_lr{args.lr}_c{args.channels}')\n",
    "\n",
    "    if args.amp:\n",
    "        out_dir += '_amp'\n",
    "\n",
    "    if args.cupy:\n",
    "        out_dir += '_cupy'\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        print(f'Mkdir {out_dir}.')\n",
    "\n",
    "    writer = SummaryWriter(out_dir, purge_step=start_epoch)\n",
    "    with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(' '.join(sys.argv))\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_samples = 0\n",
    "        for img, label in train_data_loader:\n",
    "            optimizer.zero_grad()          #reset optimizer\n",
    "            img = img.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            label_onehot = F.one_hot(label, 10).float() #one-hot encoding the label to a vector\n",
    "\n",
    "            if scaler is not None:\n",
    "                with amp.autocast():\n",
    "                    out_fr = net(img)\n",
    "                    loss = F.mse_loss(out_fr, label_onehot) #calculate the MSE loss between the prediction and the vector\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "            functional.reset_net(net)\n",
    "\n",
    "        train_time = time.time()\n",
    "        train_speed = train_samples / (train_time - start_time)\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in test_data_loader:\n",
    "                img = img.to(args.device)\n",
    "                label = label.to(args.device)\n",
    "                label_onehot = F.one_hot(label, 10).float()\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                functional.reset_net(net)\n",
    "        test_time = time.time()\n",
    "        test_speed = test_samples / (test_time - train_time)\n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "\n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "\n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
    "\n",
    "        print(args)\n",
    "        print(out_dir)\n",
    "        print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}, max_test_acc ={max_test_acc: .4f}')\n",
    "        print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n",
    "        print(f'escape time = {(datetime.datetime.now() + datetime.timedelta(seconds=(time.time() - start_time) * (args.epochs - epoch))).strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b159295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
