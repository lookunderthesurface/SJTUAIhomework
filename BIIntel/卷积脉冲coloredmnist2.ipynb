{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33791de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "CSNN(\n",
      "  (conv_fc): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=m)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (2): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=m)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (6): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1, step_mode=m)\n",
      "    (9): Linear(in_features=6272, out_features=2048, bias=False)\n",
      "    (10): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (11): Linear(in_features=2048, out_features=10, bias=False)\n",
      "    (12): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Mkdir logs/T4_b128_Adam_lr0.001_c128_amp.\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 0, train_loss = 0.0181, train_acc = 0.8797, test_loss = 0.0056, test_acc = 0.9771, max_test_acc = 0.9771\n",
      "train speed = 2879.4302 images/s, test speed = 6892.9711 images/s\n",
      "escape time = 2024-11-15 12:04:50\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 1, train_loss = 0.0046, train_acc = 0.9796, test_loss = 0.0042, test_acc = 0.9807, max_test_acc = 0.9807\n",
      "train speed = 3023.1073 images/s, test speed = 10949.3643 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 2, train_loss = 0.0034, train_acc = 0.9851, test_loss = 0.0031, test_acc = 0.9842, max_test_acc = 0.9842\n",
      "train speed = 3022.2855 images/s, test speed = 10849.3993 images/s\n",
      "escape time = 2024-11-15 12:04:19\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 3, train_loss = 0.0027, train_acc = 0.9884, test_loss = 0.0028, test_acc = 0.9854, max_test_acc = 0.9854\n",
      "train speed = 3020.5531 images/s, test speed = 10942.6370 images/s\n",
      "escape time = 2024-11-15 12:04:18\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 4, train_loss = 0.0024, train_acc = 0.9898, test_loss = 0.0029, test_acc = 0.9877, max_test_acc = 0.9877\n",
      "train speed = 3019.7880 images/s, test speed = 10762.5099 images/s\n",
      "escape time = 2024-11-15 12:04:17\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 5, train_loss = 0.0020, train_acc = 0.9910, test_loss = 0.0023, test_acc = 0.9884, max_test_acc = 0.9884\n",
      "train speed = 3021.2475 images/s, test speed = 10978.4883 images/s\n",
      "escape time = 2024-11-15 12:04:17\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 6, train_loss = 0.0017, train_acc = 0.9927, test_loss = 0.0021, test_acc = 0.9895, max_test_acc = 0.9895\n",
      "train speed = 3020.8067 images/s, test speed = 10954.2028 images/s\n",
      "escape time = 2024-11-15 12:04:18\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 7, train_loss = 0.0014, train_acc = 0.9942, test_loss = 0.0021, test_acc = 0.9895, max_test_acc = 0.9895\n",
      "train speed = 3020.2281 images/s, test speed = 11015.0815 images/s\n",
      "escape time = 2024-11-15 12:04:13\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 8, train_loss = 0.0013, train_acc = 0.9948, test_loss = 0.0019, test_acc = 0.9898, max_test_acc = 0.9898\n",
      "train speed = 3020.9824 images/s, test speed = 10912.9558 images/s\n",
      "escape time = 2024-11-15 12:04:17\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 9, train_loss = 0.0011, train_acc = 0.9958, test_loss = 0.0016, test_acc = 0.9905, max_test_acc = 0.9905\n",
      "train speed = 3019.9833 images/s, test speed = 10997.5531 images/s\n",
      "escape time = 2024-11-15 12:04:17\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 10, train_loss = 0.0009, train_acc = 0.9965, test_loss = 0.0020, test_acc = 0.9895, max_test_acc = 0.9905\n",
      "train speed = 3021.6618 images/s, test speed = 10853.1921 images/s\n",
      "escape time = 2024-11-15 12:04:13\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 11, train_loss = 0.0008, train_acc = 0.9969, test_loss = 0.0014, test_acc = 0.9930, max_test_acc = 0.9930\n",
      "train speed = 3020.6818 images/s, test speed = 10821.7091 images/s\n",
      "escape time = 2024-11-15 12:04:17\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 12, train_loss = 0.0007, train_acc = 0.9975, test_loss = 0.0014, test_acc = 0.9921, max_test_acc = 0.9930\n",
      "train speed = 3018.7474 images/s, test speed = 10997.9770 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 13, train_loss = 0.0006, train_acc = 0.9979, test_loss = 0.0015, test_acc = 0.9915, max_test_acc = 0.9930\n",
      "train speed = 3019.6202 images/s, test speed = 11002.9221 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 14, train_loss = 0.0005, train_acc = 0.9981, test_loss = 0.0015, test_acc = 0.9908, max_test_acc = 0.9930\n",
      "train speed = 3019.4949 images/s, test speed = 10845.0399 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 15, train_loss = 0.0004, train_acc = 0.9989, test_loss = 0.0013, test_acc = 0.9924, max_test_acc = 0.9930\n",
      "train speed = 3019.0579 images/s, test speed = 11005.1970 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 16, train_loss = 0.0004, train_acc = 0.9990, test_loss = 0.0014, test_acc = 0.9919, max_test_acc = 0.9930\n",
      "train speed = 3018.4221 images/s, test speed = 10787.3251 images/s\n",
      "escape time = 2024-11-15 12:04:15\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 17, train_loss = 0.0003, train_acc = 0.9991, test_loss = 0.0013, test_acc = 0.9930, max_test_acc = 0.9930\n",
      "train speed = 3019.4473 images/s, test speed = 10972.8245 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 18, train_loss = 0.0003, train_acc = 0.9992, test_loss = 0.0012, test_acc = 0.9928, max_test_acc = 0.9930\n",
      "train speed = 3020.8545 images/s, test speed = 11001.9206 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 19, train_loss = 0.0002, train_acc = 0.9993, test_loss = 0.0012, test_acc = 0.9936, max_test_acc = 0.9936\n",
      "train speed = 3020.0701 images/s, test speed = 10807.3739 images/s\n",
      "escape time = 2024-11-15 12:04:16\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 20, train_loss = 0.0002, train_acc = 0.9995, test_loss = 0.0012, test_acc = 0.9931, max_test_acc = 0.9936\n",
      "train speed = 3020.0638 images/s, test speed = 10700.2847 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 21, train_loss = 0.0002, train_acc = 0.9997, test_loss = 0.0011, test_acc = 0.9934, max_test_acc = 0.9936\n",
      "train speed = 3021.0166 images/s, test speed = 11004.3741 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 22, train_loss = 0.0002, train_acc = 0.9996, test_loss = 0.0010, test_acc = 0.9940, max_test_acc = 0.9940\n",
      "train speed = 3017.1373 images/s, test speed = 10977.4510 images/s\n",
      "escape time = 2024-11-15 12:04:15\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 23, train_loss = 0.0002, train_acc = 0.9996, test_loss = 0.0011, test_acc = 0.9932, max_test_acc = 0.9940\n",
      "train speed = 3021.3987 images/s, test speed = 10975.9888 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n",
      "<__main__.main.<locals>.parser object at 0x7fd36dfd6410>\n",
      "logs/T4_b128_Adam_lr0.001_c128_amp\n",
      "epoch = 24, train_loss = 0.0002, train_acc = 0.9996, test_loss = 0.0011, test_acc = 0.9936, max_test_acc = 0.9940\n",
      "train speed = 3019.5386 images/s, test speed = 10820.3049 images/s\n",
      "escape time = 2024-11-15 12:04:14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "from ColorMNIST import ColorMNIST\n",
    "\n",
    "path_to_mnist = '/workspace/mnist_data/MNIST'\n",
    "\n",
    "#卷积脉冲神经网络定义\n",
    "class CSNN(nn.Module):\n",
    "    def __init__(self, T: int, channels: int, use_cupy=False):\n",
    "        super().__init__()\n",
    "        self.T = T  #SNN时间步长\n",
    "\n",
    "        self.conv_fc = nn.Sequential(\n",
    "        layer.Conv2d(3, channels, kernel_size=3, padding=1, bias=False),    #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.LIFNode(tau=2., surrogate_function=surrogate.ATan()),                 # IF脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 14 * 14                                   # 最大池化\n",
    "\n",
    "        layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False), #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.LIFNode(tau=2., surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 7 * 7                                     # 最大池化\n",
    "\n",
    "        layer.Flatten(),\n",
    "        layer.Linear(channels * 7 * 7, channels * 4 * 4, bias=False),       #普通线性层\n",
    "        neuron.LIFNode(tau=2., surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "\n",
    "        layer.Linear(channels * 4 * 4, 10, bias=False),         \n",
    "        neuron.LIFNode(tau=2., surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "        functional.set_step_mode(self, step_mode='m')                       #多步脉冲模式\n",
    "\n",
    "        if use_cupy:\n",
    "            functional.set_backend(self, backend='cupy')\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x.shape = [N, C, H, W]\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)  # [N, C, H, W] -> [T, N, C, H, W]  #将数据复制T份直接输入网络\n",
    "        x_seq = self.conv_fc(x_seq)\n",
    "        fr = x_seq.mean(0)\n",
    "        return fr\n",
    "    \n",
    "    def spiking_encoder(self):\n",
    "        return self.conv_fc[0:3] #脉冲节点即可将float输入编码为spike序列\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    (sj-dev) wfang@Precision-5820-Tower-X-Series:~/spikingjelly_dev$ python -m spikingjelly.activation_based.examples.conv_fashion_mnist -h\n",
    "\n",
    "    usage: conv_fashion_mnist.py [-h] [-T T] [-device DEVICE] [-b B] [-epochs N] [-j N] [-data-dir DATA_DIR] [-out-dir OUT_DIR]\n",
    "                                 [-resume RESUME] [-amp] [-cupy] [-opt OPT] [-momentum MOMENTUM] [-lr LR]\n",
    "\n",
    "    Classify Fashion-MNIST\n",
    "\n",
    "    optional arguments:\n",
    "      -h, --help          show this help message and exit\n",
    "      -T T                simulating time-steps\n",
    "      -device DEVICE      device\n",
    "      -b B                batch size\n",
    "      -epochs N           number of total epochs to run\n",
    "      -j N                number of data loading workers (default: 4)\n",
    "      -data-dir DATA_DIR  root dir of Fashion-MNIST dataset\n",
    "      -out-dir OUT_DIR    root dir for saving logs and checkpoint\n",
    "      -resume RESUME      resume from the checkpoint path\n",
    "      -amp                automatic mixed precision training\n",
    "      -cupy               use cupy neuron and multi-step forward mode\n",
    "      -opt OPT            use which optimizer. SDG or Adam\n",
    "      -momentum MOMENTUM  momentum for SGD\n",
    "      -save-es            dir for saving a batch spikes encoded by the first {Conv2d-BatchNorm2d-IFNode}\n",
    "    '''\n",
    "    # python -m spikingjelly.activation_based.examples.conv_fashion_mnist -T 4 -device cuda:0 -b 128 -epochs 64 -data-dir /datasets/FashionMNIST/ -amp -cupy -opt sgd -lr 0.1 -j 8\n",
    "\n",
    "    # python -m spikingjelly.activation_based.examples.conv_fashion_mnist -T 4 -device cuda:0 -b 4 -epochs 64 -data-dir /datasets/FashionMNIST/ -amp -cupy -opt sgd -lr 0.1 -j 8 -resume ./logs/T4_b256_sgd_lr0.1_c128_amp_cupy/checkpoint_latest.pth -save-es ./logs\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description='Classify Fashion-MNIST')\n",
    "    parser.add_argument('-T', default=4, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', default=128, type=int, help='batch size')\n",
    "    parser.add_argument('-epochs', default=64, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('-data-dir', type=str, help='root dir of Fashion-MNIST dataset')\n",
    "    parser.add_argument('-out-dir', type=str, default='./logs', help='root dir for saving logs and checkpoint')\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    parser.add_argument('-amp', action='store_true', help='automatic mixed precision training')\n",
    "    parser.add_argument('-cupy', action='store_true', help='use cupy backend')\n",
    "    parser.add_argument('-opt', type=str, help='use which optimizer. SDG or Adam')\n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-lr', default=0.1, type=float, help='learning rate')\n",
    "    parser.add_argument('-channels', default=128, type=int, help='channels of CSNN')\n",
    "    parser.add_argument('-save-es', default=None, help='dir for saving a batch spikes encoded by the first {Conv2d-BatchNorm2d-IFNode}')\n",
    "    '''\n",
    "    \n",
    "    class parser():\n",
    "        def __init__(self):\n",
    "            self.T = 4\n",
    "            self.device = 'cuda:0'# 'cpu'\n",
    "            self.b = 128\n",
    "            self.epochs = 25\n",
    "            self.j = 4\n",
    "            self.data_dir='/workspace/fashionmnist'\n",
    "            self.out_dir='logs'\n",
    "            self.resume = 'None'\n",
    "            self.amp = True#False\n",
    "            self.cupy = False\n",
    "            self.opt = 'Adam'\n",
    "            self.momentum = 0.9\n",
    "            self.lr = 0.001\n",
    "            self.channels = 128\n",
    "            self.save_es = None\n",
    "    \n",
    "    #args = parser.parse_args()\n",
    "    args = parser()\n",
    "    print(args)\n",
    "\n",
    "    net = CSNN(T=args.T, channels=args.channels, use_cupy=args.cupy)\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    net.to(args.device)\n",
    "    \n",
    "    '''\n",
    "    载入数据，和普通DNN的训练步骤一样\n",
    "    '''\n",
    "\n",
    "    train_set = ColorMNIST('both', 'train', path_to_mnist, randomcolor=True)\n",
    "    test_set = ColorMNIST('both', 'test', path_to_mnist, randomcolor=True)\n",
    "    # train_set = torchvision.datasets.FashionMNIST(\n",
    "    #         root=args.data_dir,\n",
    "    #         train=True,\n",
    "    #         transform=torchvision.transforms.ToTensor(),\n",
    "    #         download=True)\n",
    "\n",
    "    # test_set = torchvision.datasets.FashionMNIST(\n",
    "    #         root=args.data_dir,\n",
    "    #         train=False,\n",
    "    #         transform=torchvision.transforms.ToTensor(),\n",
    "    #         download=True)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=args.b,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=args.b,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=args.j,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "\n",
    "    scaler = None\n",
    "    if args.amp:\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "    start_epoch = 0\n",
    "    max_test_acc = -1\n",
    "\n",
    "    '''\n",
    "    定义优化器，和普通DNN的训练步骤一样\n",
    "    '''\n",
    "    \n",
    "    optimizer = None\n",
    "    if args.opt == 'sgd':\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    elif args.opt == 'Adam':\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        raise NotImplementedError(args.opt)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "\n",
    "\n",
    "    out_dir = os.path.join(args.out_dir, f'T{args.T}_b{args.b}_{args.opt}_lr{args.lr}_c{args.channels}')\n",
    "\n",
    "    if args.amp:\n",
    "        out_dir += '_amp'\n",
    "\n",
    "    if args.cupy:\n",
    "        out_dir += '_cupy'\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        print(f'Mkdir {out_dir}.')\n",
    "\n",
    "    writer = SummaryWriter(out_dir, purge_step=start_epoch)\n",
    "    with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(' '.join(sys.argv))\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_samples = 0\n",
    "        for img, label in train_data_loader:\n",
    "            optimizer.zero_grad()          #reset optimizer\n",
    "            img = img.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            label_onehot = F.one_hot(label, 10).float() #one-hot encoding the label to a vector\n",
    "\n",
    "            if scaler is not None:\n",
    "                with amp.autocast(device_type='cuda'):\n",
    "                    out_fr = net(img)\n",
    "                    loss = F.mse_loss(out_fr, label_onehot) #calculate the MSE loss between the prediction and the vector\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "            functional.reset_net(net)\n",
    "\n",
    "        train_time = time.time()\n",
    "        train_speed = train_samples / (train_time - start_time)\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in test_data_loader:\n",
    "                img = img.to(args.device)\n",
    "                label = label.to(args.device)\n",
    "                label_onehot = F.one_hot(label, 10).float()\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                functional.reset_net(net)\n",
    "        test_time = time.time()\n",
    "        test_speed = test_samples / (test_time - train_time)\n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "\n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "\n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
    "\n",
    "        print(args)\n",
    "        print(out_dir)\n",
    "        print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}, max_test_acc ={max_test_acc: .4f}')\n",
    "        print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n",
    "        print(f'escape time = {(datetime.datetime.now() + datetime.timedelta(seconds=(time.time() - start_time) * (args.epochs - epoch))).strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b159295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
